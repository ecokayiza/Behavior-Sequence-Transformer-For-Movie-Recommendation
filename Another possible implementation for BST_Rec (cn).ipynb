{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "users = pd.read_csv(\n",
    "    \"ml-1m/users.dat\",\n",
    "    sep=\"::\",\n",
    "    names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"],\n",
    "    engine='python'\n",
    ")\n",
    "\n",
    "movies = pd.read_csv(\n",
    "    \"ml-1m/movies.dat\", sep=\"::\", names=[\"movie_id\", \"title\", \"genres\"],\n",
    "    engine='python',encoding='ISO-8859-1'\n",
    ")\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    \"ml-1m/ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    names=[\"user_id\", \"movie_id\", \"rating\", \"unix_timestamp\"],\n",
    "    engine='python'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e07ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users data:\n",
      "   user_id sex  age_group  occupation zip_code\n",
      "0        1   F          1          10    48067\n",
      "1        2   M         56          16    70072\n",
      "2        3   M         25          15    55117\n",
      "3        4   M         45           7    02460\n",
      "4        5   M         25          20    55455\n",
      "\n",
      "Movies data:\n",
      "   movie_id                               title                        genres\n",
      "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4         5  Father of the Bride Part II (1995)                        Comedy\n",
      "\n",
      "Ratings data:\n",
      "   user_id  movie_id  rating  unix_timestamp\n",
      "0        1      1193       5       978300760\n",
      "1        1       661       3       978302109\n",
      "2        1       914       3       978301968\n",
      "3        1      3408       4       978300275\n",
      "4        1      2355       5       978824291\n"
     ]
    }
   ],
   "source": [
    "print(\"Users data:\")\n",
    "print(users.head())\n",
    "print(\"\\nMovies data:\")\n",
    "print(movies.head())\n",
    "print(\"\\nRatings data:\")\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2ef0880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将原始ID转换为连续的索引，便于embedding层使用\n",
    "def generate_remap_id_dict(df,col):\n",
    "    ids = df[df[col].notnull()][col].unique().tolist()\n",
    "    ids = sorted(ids)\n",
    "    id_map_dict = {x: i+1 for i, x in enumerate(ids)}\n",
    "    id_map_dict[\"UNK\"]=0\n",
    "    df[f\"{col}_index\"] = df[col].fillna(\"UNK\").map(id_map_dict)\n",
    "    return id_map_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bba3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_map_dict=generate_remap_id_dict(users,col='user_id')\n",
    "user_sex_map_dict=generate_remap_id_dict(users,col='sex')\n",
    "user_age_group_map_dict=generate_remap_id_dict(users,col='age_group')\n",
    "user_occupation_map_dict=generate_remap_id_dict(users,col='occupation')\n",
    "movie_id_map_dict = generate_remap_id_dict(movies,col='movie_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f21065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "ratings[\"norm_rating\"] = min_max_scaler.fit_transform(\n",
    "    ratings[\"rating\"].values.reshape(-1, 1))[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09e1ff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>user_id_index</th>\n",
       "      <th>sex_index</th>\n",
       "      <th>age_group_index</th>\n",
       "      <th>occupation_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id sex  age_group  occupation zip_code  user_id_index  sex_index  \\\n",
       "0        1   F          1          10    48067              1          1   \n",
       "1        2   M         56          16    70072              2          2   \n",
       "2        3   M         25          15    55117              3          2   \n",
       "3        4   M         45           7    02460              4          2   \n",
       "4        5   M         25          20    55455              5          2   \n",
       "\n",
       "   age_group_index  occupation_index  \n",
       "0                1                11  \n",
       "1                7                17  \n",
       "2                3                16  \n",
       "3                5                 8  \n",
       "4                3                21  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3961b083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_index</th>\n",
       "      <th>sex_index</th>\n",
       "      <th>age_group_index</th>\n",
       "      <th>occupation_index</th>\n",
       "      <th>movie_id_index</th>\n",
       "      <th>norm_rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1177</td>\n",
       "      <td>1.00</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>656</td>\n",
       "      <td>0.50</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>903</td>\n",
       "      <td>0.50</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3340</td>\n",
       "      <td>0.75</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2287</td>\n",
       "      <td>1.00</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id_index  sex_index  age_group_index  occupation_index  \\\n",
       "0              1          1                1                11   \n",
       "1              1          1                1                11   \n",
       "2              1          1                1                11   \n",
       "3              1          1                1                11   \n",
       "4              1          1                1                11   \n",
       "\n",
       "   movie_id_index  norm_rating  unix_timestamp  \n",
       "0            1177         1.00       978300760  \n",
       "1             656         0.50       978302109  \n",
       "2             903         0.50       978301968  \n",
       "3            3340         0.75       978300275  \n",
       "4            2287         1.00       978824291  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_full_matrix = users.merge(ratings[['user_id', 'movie_id', 'norm_rating','unix_timestamp']], on='user_id', how='left')\n",
    "df_user_full_matrix['movie_id_index'] = ratings['movie_id'].map(movie_id_map_dict)\n",
    "df_user_full_matrix['user_id_index'] = ratings['user_id'].map(user_id_map_dict)\n",
    "df_user_full_matrix['sex_index'] = df_user_full_matrix['sex'].map(user_sex_map_dict)\n",
    "df_user_full_matrix['age_group_index'] = df_user_full_matrix['age_group'].map(user_age_group_map_dict)\n",
    "df_user_full_matrix['occupation_index'] = df_user_full_matrix['occupation'].map(user_occupation_map_dict)\n",
    "df_user_full_matrix = df_user_full_matrix[['user_id_index', 'sex_index', 'age_group_index', 'occupation_index', 'movie_id_index', 'norm_rating','unix_timestamp']]\n",
    "df_user_full_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4508b6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_index</th>\n",
       "      <th>sex_index</th>\n",
       "      <th>age_group_index</th>\n",
       "      <th>occupation_index</th>\n",
       "      <th>movie_id_index</th>\n",
       "      <th>norm_rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3118</td>\n",
       "      <td>0.75</td>\n",
       "      <td>978300019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1251</td>\n",
       "      <td>1.00</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1673</td>\n",
       "      <td>0.75</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1010</td>\n",
       "      <td>1.00</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2272</td>\n",
       "      <td>0.50</td>\n",
       "      <td>978300103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id_index  sex_index  age_group_index  occupation_index  \\\n",
       "31              1          1                1                11   \n",
       "22              1          1                1                11   \n",
       "27              1          1                1                11   \n",
       "37              1          1                1                11   \n",
       "24              1          1                1                11   \n",
       "\n",
       "    movie_id_index  norm_rating  unix_timestamp  \n",
       "31            3118         0.75       978300019  \n",
       "22            1251         1.00       978300055  \n",
       "27            1673         0.75       978300055  \n",
       "37            1010         1.00       978300055  \n",
       "24            2272         0.50       978300103  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort with user_id and unix_timestamp\n",
    "df_user_full_matrix = df_user_full_matrix.sort_values(['user_id_index', 'unix_timestamp'])\n",
    "df_user_full_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77bda42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_index</th>\n",
       "      <th>movie_sequence</th>\n",
       "      <th>rating_sequence</th>\n",
       "      <th>sex_index</th>\n",
       "      <th>age_group_index</th>\n",
       "      <th>occupation_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[3118, 1251, 1673, 1010]</td>\n",
       "      <td>[0.75, 1.0, 0.75, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1673, 1010, 2272, 1769]</td>\n",
       "      <td>[0.75, 1.0, 0.5, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2272, 1769, 3340, 2736]</td>\n",
       "      <td>[0.5, 1.0, 0.75, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[3340, 2736, 1190, 1177]</td>\n",
       "      <td>[0.75, 1.0, 0.75, 1.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1190, 1177, 712, 258]</td>\n",
       "      <td>[0.75, 1.0, 0.5, 0.75]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id_index            movie_sequence         rating_sequence  sex_index  \\\n",
       "0              1  [3118, 1251, 1673, 1010]  [0.75, 1.0, 0.75, 1.0]          1   \n",
       "1              1  [1673, 1010, 2272, 1769]   [0.75, 1.0, 0.5, 1.0]          1   \n",
       "2              1  [2272, 1769, 3340, 2736]   [0.5, 1.0, 0.75, 1.0]          1   \n",
       "3              1  [3340, 2736, 1190, 1177]  [0.75, 1.0, 0.75, 1.0]          1   \n",
       "4              1    [1190, 1177, 712, 258]  [0.75, 1.0, 0.5, 0.75]          1   \n",
       "\n",
       "   age_group_index  occupation_index  \n",
       "0                1                11  \n",
       "1                1                11  \n",
       "2                1                11  \n",
       "3                1                11  \n",
       "4                1                11  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_sequence_data(df, window_size, step):\n",
    "    sequences = []\n",
    "    \n",
    "    for user_id, user_data in df.groupby('user_id_index'):\n",
    "        user_data = user_data.reset_index(drop=True)\n",
    "    \n",
    "        for i in range(0, len(user_data) - window_size + 1, step):\n",
    "            sequence = user_data.iloc[i:i + window_size]\n",
    "            \n",
    "            movie_sequence = sequence['movie_id_index'].tolist()\n",
    "            rating_sequence = sequence['norm_rating'].tolist()\n",
    "            \n",
    "            sequences.append({\n",
    "                'user_id_index': user_id,\n",
    "                'movie_sequence': movie_sequence,\n",
    "                'rating_sequence': rating_sequence,\n",
    "                'sex_index': sequence['sex_index'].iloc[0],\n",
    "                'age_group_index': sequence['age_group_index'].iloc[0],\n",
    "                'occupation_index': sequence['occupation_index'].iloc[0]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(sequences)\n",
    "df_user_view = gen_sequence_data(df_user_full_matrix,window_size=4,step=2)\n",
    "df_user_view.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e4222d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419142 73441\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "random_selection = np.random.rand(len(df_user_view)) <= 0.85\n",
    "train_data = df_user_view[random_selection]\n",
    "test_data = df_user_view[~random_selection]\n",
    "print(len(train_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, List, Optional, Union\n",
    "import math\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    BST模型的统一Embedding层\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 embed_configs: Dict[str, Dict],\n",
    "                 dropout: float = 0.2,\n",
    "                 initialization: str = \"xavier\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_configs = embed_configs\n",
    "        self.dropout = dropout\n",
    "        self.embed_dim = embed_configs['position']['embed_dim']\n",
    "        self.seq_len = embed_configs['position']['num_embed']\n",
    "        \n",
    "        \n",
    "        # 创建embedding层\n",
    "        self.embeddings = nn.ModuleDict() # 各特征的Embedding\n",
    "        self.feature_types = {}\n",
    "        \n",
    "        for feature_name, config in embed_configs.items():\n",
    "            embed_dim_feat = config.get('embed_dim',self.embed_dim)\n",
    "            num_embeddings = config['num_embed']\n",
    "            feature_type = config.get('type', 'categorical')\n",
    "            \n",
    "            # 根据特征类型创建不同的embedding\n",
    "            if feature_type == 'categorical':\n",
    "                self.embeddings[feature_name] = nn.Embedding(\n",
    "                    num_embeddings, embed_dim_feat, padding_idx=0\n",
    "                )\n",
    "            elif feature_type == 'sequence':\n",
    "                # 序列特征\n",
    "                self.embeddings[feature_name] = SequenceEmbedding(\n",
    "                    num_embeddings, embed_dim_feat\n",
    "                )\n",
    "            \n",
    "            self.feature_types[feature_name] = feature_type\n",
    "            \n",
    "            # 初始化embedding权重\n",
    "            self._init_embedding(self.embeddings[feature_name], initialization)\n",
    "            # inner\n",
    "        # outer\n",
    "        # Dropout层\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # cal dims\n",
    "        total_dim = 0\n",
    "        transformer_dim = 0\n",
    "        for k,v in embed_configs.items():\n",
    "            total_dim += v[\"embed_dim\"]\n",
    "            if k == 'item' or k =='position':\n",
    "                transformer_dim += v[\"embed_dim\"]\n",
    "        total_dim += embed_configs['item']['embed_dim']\n",
    "        self.total_dim = total_dim\n",
    "        self.transformer_dim = transformer_dim\n",
    "        \n",
    "        \n",
    "    def _init_embedding(self, embedding_layer, init_type):\n",
    "        \"\"\"初始化embedding权重\"\"\"\n",
    "        if hasattr(embedding_layer, 'weight'):\n",
    "            if init_type == \"xavier\":\n",
    "                nn.init.xavier_uniform_(embedding_layer.weight)\n",
    "            elif init_type == \"normal\":\n",
    "                nn.init.normal_(embedding_layer.weight, std=0.1)\n",
    "            elif init_type == \"kaiming\":\n",
    "                nn.init.kaiming_uniform_(embedding_layer.weight)\n",
    "    \n",
    "    def forward(self, features: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        embeddings = {}\n",
    "        \n",
    "        for feature_name, feature_tensor in features.items():\n",
    "            if feature_name in self.embeddings:\n",
    "                # 获取embedding\n",
    "                embed = self.embeddings[feature_name](feature_tensor)\n",
    "                # 应用dropout\n",
    "                embed = self.embedding_dropout(embed)\n",
    "                embeddings[feature_name] = embed\n",
    "        return embeddings\n",
    "    \n",
    "class SequenceEmbedding(nn.Module):\n",
    "    def __init__(self, num_item, embed_dim,seq_length):\n",
    "        super().__init__()\n",
    "        self.item_embedding = nn.Embedding(num_item, embed_dim, padding_idx=0)\n",
    "        \n",
    "        self.position_embedding = nn.Embedding(seq_length, embed_dim)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(embed_dim * 2)  # 拼接\n",
    "        \n",
    "    def forward(self, movie_sequence, rating_sequence=None):\n",
    "        batch_size, seq_len = movie_sequence.shape\n",
    "        \n",
    "        item_embeds = self.item_embedding(movie_sequence)  # (B, L, D)\n",
    "        \n",
    "        # Position embeddings\n",
    "        positions = torch.arange(seq_len, device=movie_sequence.device)\n",
    "        pos_embeds = self.position_embedding(positions).unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        \n",
    "        # concat\n",
    "        sequence_embeds = torch.cat([item_embeds, pos_embeds], dim=-1)  # (B, L, 2*D)\n",
    "        \n",
    "        # Optional: Rating weighting (BST uses ratings as attention weights)\n",
    "        if rating_sequence is not None:\n",
    "            rating_weights = rating_sequence.unsqueeze(-1)  # (B, L, 1)\n",
    "            sequence_embeds = sequence_embeds * rating_weights\n",
    "            \n",
    "        return self.layer_norm(sequence_embeds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9674b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding config\n",
    "\n",
    "num_user = len(user_id_map_dict)\n",
    "num_movie = len(movie_id_map_dict)\n",
    "num_occupation = len(user_occupation_map_dict)\n",
    "num_age_group = len(user_age_group_map_dict)\n",
    "num_sex = len(user_sex_map_dict)\n",
    "\n",
    "embed_configs = {}\n",
    "EMED_DIM=32\n",
    "SEQUENCE_SIZE = 4\n",
    "embed_configs['item']={\"embed_dim\":EMED_DIM,\"num_embed\":num_movie}\n",
    "embed_configs['position'] = {\"embed_dim\":EMED_DIM,\"num_embed\":SEQUENCE_SIZE}\n",
    "\n",
    "embed_configs['user']={\"embed_dim\":EMED_DIM,\"num_embed\":num_user}\n",
    "embed_configs['sex'] = {\"embed_dim\": EMED_DIM, \"num_embed\":num_sex }\n",
    "embed_configs['occupation']={\"embed_dim\":EMED_DIM,\"num_embed\":num_occupation}\n",
    "embed_configs['age_group']={\"embed_dim\":EMED_DIM,\"num_embed\":num_age_group}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ba10f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleDict(\n",
      "  (item): Embedding(3884, 32, padding_idx=0)\n",
      "  (position): Embedding(4, 32, padding_idx=0)\n",
      "  (user): Embedding(6041, 32, padding_idx=0)\n",
      "  (sex): Embedding(3, 32, padding_idx=0)\n",
      "  (occupation): Embedding(22, 32, padding_idx=0)\n",
      "  (age_group): Embedding(8, 32, padding_idx=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = EmbeddingLayer(embed_configs)\n",
    "print(embedding_layer.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e39095af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_heads, dropout_rate):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.multihead_attention = nn.MultiheadAttention(input_size, num_heads)\n",
    "        self.layer_norm1 = nn.LayerNorm(input_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(input_size, 4*input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*input_size, output_size),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.layer_norm2 = nn.LayerNorm(output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multi-head Attention\n",
    "        attn_output, _ = self.multihead_attention(x, x, x)\n",
    "        x = self.layer_norm1(x + attn_output)\n",
    "\n",
    "        # Feed-Forward Network\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.layer_norm2(x + ff_output)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads=8, dropout_rate=0.2, num_layers=3):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(d_model, d_model, num_heads, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f1ceecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dropout=0.2, hidden_units=[512, 256,128]):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_units) - 1):\n",
    "            self.layers.append(nn.Linear(hidden_units[i], hidden_units[i + 1]))\n",
    "            self.layers.append(nn.LeakyReLU())\n",
    "            self.layers.append(nn.Dropout(p=dropout))\n",
    "        self.fc = nn.Linear(hidden_units[-1],1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        logits = self.fc(x)\n",
    "        output = self.sigmoid(logits)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSTRecommender(nn.Module):    \n",
    "    def __init__(self,embedding_layer,num_heads=8,transformer_num_layer=3,drop_out=0.2):\n",
    "        super().__init__()\n",
    "        # Embedding params\n",
    "        self.seq_len = embedding_layer.seq_len\n",
    "        self.totoal_dim = embedding_layer.total_dim\n",
    "        self.transformer_dim = embedding_layer.transformer_dim\n",
    "        \n",
    "        self.drouput = drop_out\n",
    "        self.num_heads = num_heads\n",
    "        self.transformer_num_layer = transformer_num_layer\n",
    "        \n",
    "        # Embedding\n",
    "        self.embedding_layer = embedding_layer\n",
    "        \n",
    "        # Transformer\n",
    "        self.transformer_layer = TransformerLayer(d_model=self.transformer_dim,\n",
    "                                            num_heads=self.num_heads,\n",
    "                                            dropout_rate=self.drouput,\n",
    "                                            num_layers=self.transformer_num_layer)\n",
    "        \n",
    "        # MLP\n",
    "        self.mlp = MLP(dropout=self.drouput, hidden_units=[self.totoal_dim, 256, 64])\n",
    "            \n",
    "    def forward(self, batch):\n",
    "        batch_size = batch['movie_sequence'].shape[0]\n",
    "        # 1. 用户特征embedding\n",
    "        user_features = {\n",
    "            'user': batch['user_id_index'],\n",
    "            'occupation': batch['occupation_index'],\n",
    "            'age_group': batch['age_group_index'],\n",
    "            'sex': batch['sex']\n",
    "        }\n",
    "        user_embeddings_dict = self.embedding_layer(user_features)\n",
    "        # 2. seq embeds\n",
    "        movie_embeds = self.embedding_layer.embeddings['item'](batch['movie_sequence'])\n",
    "        position_ids = torch.arange(self.seq_len, device=batch['movie_sequence'].device).unsqueeze(0).expand(batch_size, -1)\n",
    "        position_embeds = self.embedding_layer.embeddings['position'](position_ids)\n",
    "        # concat\n",
    "        sequence_embeds = torch.cat([movie_embeds, position_embeds], dim=-1)\n",
    "        \n",
    "        # Apply rating weights\n",
    "        if 'rating_sequence' in batch:\n",
    "            rating_weights = batch['rating_sequence'].unsqueeze(-1)\n",
    "            sequence_embeds = sequence_embeds * rating_weights\n",
    "        \n",
    "        # 3. Transformer编码\n",
    "        transformer_output = self.transformer_layer(sequence_embeds)\n",
    "        # 4. 序列pooling (取最后一个位置)\n",
    "        sequence_pooled = transformer_output[:, -1, :]  # Take last position\n",
    "        # 5. 目标电影embedding\n",
    "        target_movie_embed = self.embedding_layer.embeddings['item'](batch['target_movie'])\n",
    "        # 6. 特征融合 - concatenate all features (FIXED)\n",
    "        feature_list = []\n",
    "        # Add user embeddings (including sex embedding)\n",
    "        for embed in user_embeddings_dict.values():\n",
    "            feature_list.append(embed)\n",
    "        # Add sequence features\n",
    "        feature_list.append(sequence_pooled)\n",
    "        # Add target movie\n",
    "        feature_list.append(target_movie_embed)\n",
    "        features = torch.cat(feature_list, dim=-1)\n",
    "        \n",
    "        # 7. MLP预测\n",
    "        output = self.mlp(features)  # Use self.mlp, not self.mlp_predictor\n",
    "        \n",
    "        return output.squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "52bfae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BSTRecommender(\n",
       "  (embedding_layer): EmbeddingLayer(\n",
       "    (embeddings): ModuleDict(\n",
       "      (item): Embedding(3884, 32, padding_idx=0)\n",
       "      (position): Embedding(4, 32, padding_idx=0)\n",
       "      (user): Embedding(6041, 32, padding_idx=0)\n",
       "      (sex): Embedding(3, 32, padding_idx=0)\n",
       "      (occupation): Embedding(22, 32, padding_idx=0)\n",
       "      (age_group): Embedding(8, 32, padding_idx=0)\n",
       "    )\n",
       "    (embedding_dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer_layer): TransformerLayer(\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0-2): 3 x TransformerBlock(\n",
       "        (multihead_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=224, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "model = BSTRecommender(embedding_layer=embedding_layer)\n",
    "model.to(DEVICE)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9c9fa12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BSTDataset(Dataset):\n",
    "    def __init__(self, data, device):\n",
    "        self.data = data\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            'user_id_index': torch.tensor(row['user_id_index'], dtype=torch.long).to(self.device),\n",
    "            'occupation_index': torch.tensor(row['occupation_index'], dtype=torch.long).to(self.device),\n",
    "            'age_group_index': torch.tensor(row['age_group_index'], dtype=torch.long).to(self.device),\n",
    "            'sex': torch.tensor(row['sex_index'], dtype=torch.long).to(self.device),\n",
    "            'movie_sequence': torch.tensor(row['movie_sequence'], dtype=torch.long).to(self.device),\n",
    "            'rating_sequence': torch.tensor(row['rating_sequence'], dtype=torch.float).to(self.device),\n",
    "            'target_movie': torch.tensor(row['movie_sequence'][-1], dtype=torch.long).to(self.device),  # Last movie as target\n",
    "            'target_rating': torch.tensor(row['rating_sequence'][-1], dtype=torch.float).to(self.device)  # Last rating as target\n",
    "        }\n",
    "# Create datasets\n",
    "train_dataset = BSTDataset(train_data.reset_index(drop=True), DEVICE)\n",
    "test_dataset = BSTDataset(test_data.reset_index(drop=True), DEVICE)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4c1a3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()  # or nn.L1Loss() for MAE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7626d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/3275 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 3275/3275 [04:15<00:00, 12.83it/s, loss=7.08e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 3275/3275 [04:13<00:00, 12.92it/s, loss=0.000285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 3275/3275 [04:06<00:00, 13.27it/s, loss=0.000127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 3275/3275 [04:04<00:00, 13.42it/s, loss=0.000118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 3275/3275 [04:17<00:00, 12.74it/s, loss=0.000114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 3275/3275 [04:13<00:00, 12.90it/s, loss=0.000575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 3275/3275 [04:15<00:00, 12.83it/s, loss=0.000135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 3275/3275 [04:11<00:00, 13.04it/s, loss=0.000195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.0004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 3275/3275 [04:06<00:00, 13.28it/s, loss=9.65e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 3275/3275 [04:04<00:00, 13.38it/s, loss=0.000195]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Average Loss: 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(batch)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(predictions, batch['target_rating'])\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3d5d4af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 574/574 [00:40<00:00, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0003\n",
      "MAE: 0.0035\n",
      "RMSE: 0.0184\n",
      "Model saved as bst_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# test it \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    predictions_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        predictions = model(batch)\n",
    "        loss = criterion(predictions, batch['target_rating'])\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        predictions_list.extend(predictions.cpu().numpy())\n",
    "        targets_list.extend(batch['target_rating'].cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "# Calculate additional metrics\n",
    "\n",
    "mae = mean_absolute_error(targets_list, predictions_list)\n",
    "rmse = np.sqrt(mean_squared_error(targets_list, predictions_list))\n",
    "print(f'MAE: {mae:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'bst_model.pth')\n",
    "print('Model saved as bst_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
